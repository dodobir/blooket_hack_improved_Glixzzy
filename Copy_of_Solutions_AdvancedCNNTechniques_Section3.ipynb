{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dodobir/blooket_hack_improved_Glixzzy/blob/master/Copy_of_Solutions_AdvancedCNNTechniques_Section3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hwnKIOozmcZ"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEbymFK-I3jk"
      },
      "source": [
        "# Fake it 'til you make it!\n",
        "\n",
        "\n",
        "CNNs often require a LOT of data to train on, more data than a researcher or organization might have available.\n",
        "\n",
        "However we can trick our model into thinking we have more data than we do! This notebook will involve using two advanced techniques to simulate additional data: data augmentation and transfer learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtkJ7ZLHe3t0"
      },
      "source": [
        "<font color=darkorange size=5>**BEFORE RUNNING CODE: Change Hardware Accelerator to GPU to train faster (Runtime -> Change Runtime Type -> Hardware Accelerator -> T4 GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HX4E06BZOSzc"
      },
      "outputs": [],
      "source": [
        "# @title # **Run this code cell to set up the notebook!**\n",
        "# @markdown The data may take some time to load in, so feel free to move on to the next part in the meantime.\n",
        "\n",
        "project = \"histology\" # @param [\"Choose your dataset!\", \"bees\", \"histology\", \"beans\", \"malaria\"]\n",
        "\n",
        "import requests\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.image import resize_with_pad, ResizeMethod\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from skimage import data, color\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def ProjectDescription(project):\n",
        "  display_str =  f\"**[{project.capitalize()} Project Background Document]({article_url_dict[project]})** <br />\"\n",
        "  display_str += f\"**[{project.capitalize()} Dataset Documentation]({dataset_documentation_url_dict[project]})** <br />\"\n",
        "  display(Markdown(display_str))\n",
        "  response = requests.get(image_url_dict[project], stream=True)\n",
        "  img = Image.open(response.raw)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def plot_metric(history, metric=\"accuracy\", best_is_max=True, start_epoch=0, random_model_metric=None):\n",
        "  # Get lists of accuracies over the epochs\n",
        "  training_accuracy = history.history[metric][start_epoch:]\n",
        "  validation_accuracy = history.history['val_' + metric][start_epoch:]\n",
        "\n",
        "  # Find best epoch depending on whether max is the best for the metric\n",
        "  if best_is_max:\n",
        "    best_epoch = validation_accuracy.index(max(validation_accuracy))\n",
        "  else:\n",
        "    best_epoch = validation_accuracy.index(min(validation_accuracy))\n",
        "\n",
        "  # Plot labels\n",
        "  plt.title(metric.capitalize() + ' as Model Trains')\n",
        "  plt.xlabel('Epoch #')\n",
        "  plt.ylabel(metric.capitalize())\n",
        "\n",
        "  # Plot lines\n",
        "  plt.plot(training_accuracy, label='Train')\n",
        "  plt.plot(validation_accuracy, label='Validation')\n",
        "  plt.axvline(x=best_epoch, linestyle='--', color='green', label='Best Epoch')\n",
        "\n",
        "  if random_model_metric is not None:\n",
        "    plt.axhline(random_model_metric, linestyle='--',color='red', label='Chance')\n",
        "\n",
        "  # Plot legend and show\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# URL dictionaries for the projects\n",
        "article_url_dict = {\n",
        "    \"beans\"     : \"https://docs.google.com/document/d/19AcNUO-9F4E9Jtc4bvFslGhyuM5pLxjCqKYV3rUaiCc/edit?usp=sharing\",\n",
        "    \"malaria\"   : \"https://docs.google.com/document/d/1u_iX2oDrEZ1clhFefpP3V8uwAjf7EUV4G6kq_3JDcVY/edit?usp=sharing\",\n",
        "    \"histology\" : \"https://docs.google.com/document/d/162WhUE9KqCgq_I7-VvENZD2n1IVsbeXVRSwfJEkxAqQ/edit?usp=sharing\",\n",
        "    \"bees\"      : \"https://docs.google.com/document/d/1PUB_JuYHi6zyHsWAhkIb7D7ExeB1EfI09arc6Ad1bUY/edit?usp=sharing\"\n",
        "}\n",
        "\n",
        "image_url_dict = {\n",
        "    \"beans\"     : \"https://storage.googleapis.com/tfds-data/visualization/fig/beans-0.1.0.png\",\n",
        "    \"malaria\"   : \"https://storage.googleapis.com/tfds-data/visualization/fig/malaria-1.0.0.png\",\n",
        "    \"histology\" : \"https://storage.googleapis.com/tfds-data/visualization/fig/colorectal_histology-2.0.0.png\",\n",
        "    \"bees\"      : \"https://storage.googleapis.com/tfds-data/visualization/fig/bee_dataset-bee_dataset_300-1.0.0.png\"\n",
        "}\n",
        "\n",
        "download_url_prefix_dict = {\n",
        "    \"histology\" : \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Towards%20Precision%20Medicine/\",\n",
        "    \"bees\"      : \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Safeguarding%20Bee%20Health/\"\n",
        "}\n",
        "\n",
        "dataset_documentation_url_dict = {\n",
        "    \"beans\"     : \"https://www.tensorflow.org/datasets/catalog/beans\",\n",
        "    \"malaria\"   : \"https://www.tensorflow.org/datasets/catalog/malaria\",\n",
        "    \"bees\"      : \"https://www.tensorflow.org/datasets/catalog/bee_dataset\",\n",
        "    \"histology\" : \"https://www.tensorflow.org/datasets/catalog/colorectal_histology\",\n",
        "}\n",
        "\n",
        "# Load dataset\n",
        "if project == \"Choose your dataset!\":\n",
        "  print(\"Please choose your dataset from the dropdown menu!\")\n",
        "\n",
        "elif project == \"beans\":\n",
        "  data,  info = tfds.load('beans', split='train[:1024]', as_supervised=True, with_info=True)\n",
        "  feature_dict = info.features['label'].names\n",
        "  images = np.array([resize_with_pad(image, 128, 128, antialias=True) for image,_ in data]).astype(int)\n",
        "  labels = [feature_dict[int(label)] for image,label in data]\n",
        "\n",
        "elif project == \"malaria\":\n",
        "  data,  info = tfds.load('malaria', split='train[:1024]', as_supervised=True, with_info=True)\n",
        "  images = np.array([resize_with_pad(image, 256, 256, antialias=True) for image,_ in data]).astype(np.uint8)\n",
        "  labels = ['malaria' if label==1 else 'healthy' for image,label in data]\n",
        "\n",
        "else:\n",
        "  wget_command = f'wget -q --show-progress \"{download_url_prefix_dict[project]}'\n",
        "  !{wget_command + 'images.npy\" '}\n",
        "  !{wget_command + 'labels.npy\" '}\n",
        "\n",
        "  images = np.load('images.npy')\n",
        "  labels = np.load('labels.npy')\n",
        "\n",
        "  !rm images.npy labels.npy\n",
        "\n",
        "\n",
        "# Original preprocessing code for datasets\n",
        "\n",
        "# if project == \"histology\":\n",
        "#   data,  info = tfds.load('colorectal_histology', split='train[:1024]', as_supervised=True, with_info=True)\n",
        "#   feature_dict = info.features['label'].names\n",
        "#   images = np.array([image for image,label in data]).astype(int)\n",
        "#   labels = [feature_dict[int(label)] for image,label in data]\n",
        "\n",
        "# if project == \"bees\":\n",
        "#   data,  info = tfds.load('bee_dataset', split='train[:3200]', as_supervised=True, with_info=True)\n",
        "#   data = [(image, label) for image,label in data if label['wasps_output']==0]\n",
        "#   data1 = [(image, label) for image,label in data if label['varroa_output']==0][:500]\n",
        "#   data2 = [(image, label) for image,label in data if label['varroa_output']==1][:500]\n",
        "#   data = data1 + data2\n",
        "#   images = np.array([image for image, _ in data]).astype(int)\n",
        "#   labels = ['diseased' if label['varroa_output'] else 'healthy' for image,label in data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Zy5u1ohMCf"
      },
      "source": [
        "# PART 0: Remaking your model\n",
        "\n",
        "So that you can focus on advanced techniques in CNNs, we are going to help you out by:\n",
        "(1) Setting up your features and labels\n",
        "(2) Splitting up your data into training and testing\n",
        "(3) Constructing a similar CNN as in the previous notebook\n",
        "\n",
        "After running the following cell, you will have the variables ```X_train```, ```X_test```, ```y_train```, and ```y_test``` along with your initialized (but untrained!) model, ```cnn_model```.\n",
        "\n",
        "\n",
        "In return for this favor, you must run a couple sanity checks to make sure the dimensions of your variables, and the number of layers in your model is roughly what you expect!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cY0A73nD-m5o"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to construct your model!\n",
        "#@markdown Feel free to click \"Show code\" and edit the model with any improvements you may have made in Notebook 2!\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Conv3D, Flatten\n",
        "\n",
        "# Using the get_dummies() function to one-hot encode your labels.\n",
        "labels_ohe = np.array(pd.get_dummies(labels))\n",
        "\n",
        "# Select your feature (X) and labels (y).\n",
        "y = labels_ohe\n",
        "X = images\n",
        "\n",
        "# Split your data into training and testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "# Initialize your model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "\n",
        "# Input layer\n",
        "cnn_model.add(Input(shape=X_train.shape[1:]))\n",
        "\n",
        "# First layer\n",
        "cnn_model.add(Conv2D(8, (3,3), activation='relu', padding=\"same\"))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second layer\n",
        "cnn_model.add(Conv2D(16, (3,3), activation='relu', padding=\"same\"))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third layer\n",
        "cnn_model.add(Conv2D(32, (3,3), activation='relu', padding=\"same\"))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# # Fourth layer\n",
        "cnn_model.add(Conv2D(64, (3,3), activation='relu', padding=\"same\"))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "# Flattening layer\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Hidden (dense) layer with 32 nodes, and relu activation function.\n",
        "cnn_model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Final output layer that uses a softmax activation function.\n",
        "cnn_model.add(Dense(len(set(labels)), activation='softmax'))\n",
        "\n",
        "# Compile your model\n",
        "metrics_to_track = ['categorical_crossentropy', 'accuracy']\n",
        "cnn_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=metrics_to_track)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZRTnhnXR8i9"
      },
      "source": [
        "### Exercise 0A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBGr6n-bR-L_"
      },
      "source": [
        "Examine your data to ensure our preprocessing worked as intended.\n",
        "\n",
        "Print the dimensions of ```X_test```, ```y_test```, ```X_train``` and ```y_train```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ_-df0Mxqec"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ze8gezhyxuGF"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "print('Dim X_train:', X_train.shape)\n",
        "print('Dim y_train:', y_train.shape)\n",
        "print('Dim X_test:', X_test.shape)\n",
        "print('Dim y_test:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWABgZGHkoPB"
      },
      "source": [
        "### Exercise 0B\n",
        "Visualize the first 3 images in both ```X_train``` and ```X_test```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giDRBOPhx-w9"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZSM4TAZ9yAt5"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "print(\"X_train\")\n",
        "for i in range(3):\n",
        "  plt.imshow(X_train[i])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print(\"X_test\")\n",
        "for i in range(3):\n",
        "  plt.imshow(X_test[i])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzdG5X_k02n"
      },
      "source": [
        "### Exercise 0C\n",
        "Print the first 3 values of y_train and y_test, along with their categorical labels. We've given you a function to help transform the one-hot-encoded labels back into categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJkyDnX-ySkH"
      },
      "outputs": [],
      "source": [
        "one_hot_encoding_to_label_dict = {np.argmax(ohe):label for ohe, label in zip(labels_ohe, labels)}\n",
        "\n",
        "\n",
        "# This function takes in a vector, and outputs the label.\n",
        "def ScoreVectorToPredictions(prob_vector):\n",
        "  class_num = np.argmax(prob_vector) # Find which element in the vector has the highest score.\n",
        "  class_name = one_hot_encoding_to_label_dict[class_num] # Figure out the label that corresponds to this element.\n",
        "  return class_name, max(prob_vector) # Return the label as well as the probabilty that the model assigned to this prediction.\n",
        "\n",
        "\n",
        "\n",
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kKHSmfsxQHFV"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "one_hot_encoding_to_label_dict = {np.argmax(ohe):label for ohe, label in zip(labels_ohe, labels)}\n",
        "\n",
        "\n",
        "# This function takes in a vector, and outputs the label.\n",
        "def ScoreVectorToPredictions(prob_vector):\n",
        "  class_num = np.argmax(prob_vector) # Find which element in the vector has the highest score.\n",
        "  class_name = one_hot_encoding_to_label_dict[class_num] # Figure out the label that corresponds to this element.\n",
        "  return class_name # Return the label as well as the probabilty that the model assigned to this prediction.\n",
        "\n",
        "print(\"y train\")\n",
        "for i in range(3):\n",
        "  print(ScoreVectorToPredictions(y_train[i]))\n",
        "\n",
        "print(\"y test\")\n",
        "for i in range(3):\n",
        "  print(ScoreVectorToPredictions(y_test[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxluWdRcL0y-"
      },
      "source": [
        "## Exercise 0D\n",
        "\n",
        "Use the `.summary()` method to look at the architecture of your model. How many convolutional layers does your model contain? How many total parameters/weights will it be learning?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeGdUhIKMAPS"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3dzS7bXUMFqc"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mszZ_XAEyeeP"
      },
      "source": [
        "## Exercise 0E\n",
        "\n",
        "Retrain your model using your training data. Train your model for 10 epochs. Be sure to include the testing data as your `validation_data` and plot the model training history using `plot_metric()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6Al1V05yi9W"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl778VbCOVGD"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "history = cnn_model.fit(X_train, y_train,\n",
        "                        validation_data=(X_test, y_test), epochs=10)\n",
        "plot_metric(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odSLYwF-hJkW"
      },
      "source": [
        "# PART I: Data Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXAXd7VVeBUk"
      },
      "source": [
        "\n",
        "In data augmentation, we can use the images we already have to create more data. For example, we could blur, change the colors, or rotate images to simulate a new image of a dress, shoe, or shirt (or whatever type of images you are working with) that the model could theoretically encounter.\n",
        "\n",
        "<img src=\"http://ai.stanford.edu/blog/assets/img/posts/2020-04-20-data-augmentation/thumbnail.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTYOboV2eNiq"
      },
      "source": [
        "### Exericse 1A\n",
        "\n",
        "Write a function to transform the first image of your dataset by flipping it  upside down. You can use the ```flipud()``` function.  Then take a look at the original and augmented image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO9WhNsTgJ97"
      },
      "outputs": [],
      "source": [
        "from numpy import flipud\n",
        "\n",
        "## A function to create an augmented image from an original.\n",
        "def createAugmentedImage(original_image):\n",
        "  new_image = original_image ##### YOUR CODE HERE ########\n",
        "  return new_image\n",
        "\n",
        "# Transform the first image of your dataset using your new function.\n",
        "new_image = createAugmentedImage(X_train[0])\n",
        "\n",
        "# Let's see how your augmented image compares to the original!\n",
        "# We've filled this part in for you.\n",
        "f, ax = plt.subplots(ncols=2)\n",
        "ax[0].imshow(X_train[0])\n",
        "ax[0].set_title('New Image')\n",
        "ax[1].imshow(new_image)\n",
        "ax[1].set_title('Augmented Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o-rmwxcGgJ98"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "from numpy import flipud\n",
        "\n",
        "def createAugmentedImage(original_image):\n",
        "  new_image = flipud(original_image)\n",
        "  return new_image\n",
        "\n",
        "# Transform the first image of your dataset using your new function.\n",
        "new_image = createAugmentedImage(X_train[0])\n",
        "\n",
        "\n",
        "# Let's see how your augmented image compares to the original!\n",
        "# We've filled this part in for you.\n",
        "f, ax = plt.subplots(ncols=2)\n",
        "ax[0].imshow(X_train[0])\n",
        "ax[0].set_title('New Image')\n",
        "ax[1].imshow(new_image)\n",
        "ax[1].set_title('Augmented Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjma1J4qzsKH"
      },
      "source": [
        "### ‚≠ê BONUS ‚≠ê\n",
        "\n",
        "Using a different image transformation method to create an augmented image.   You can reuse the code above. **Note: Make sure you find an image transformation method that maintains the dimensions of your image! Otherwise it will no longer fit into your CNN.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKQf2jF-0B9J"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRNkJ6VkeBn2"
      },
      "source": [
        "### Exercise 1B\n",
        "\n",
        "Using the first 100 images in your training dataset, and your ```createAugmentedImage()``` function, create an augmented dataset.  \n",
        "\n",
        "You'll need to also get the associated labels for your augmented dataset. (Note: do not augment the y-values/labels at all, we want these to stay the same!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUrpJlOL159F"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "  new_X = None ### YOUR CODE HERE - What will you do to each image?\n",
        "  new_y = None ### YOUR CODE HERE\n",
        "\n",
        "  if i == 0:\n",
        "    X_train_augment = [new_X]\n",
        "    y_train_augment = [new_y]\n",
        "  else:\n",
        "    X_train_augment = np.append(X_train_augment, [new_X], axis=0)\n",
        "    y_train_augment = np.append(y_train_augment, [new_y], axis=0)\n",
        "\n",
        "\n",
        "print(\"Dimensions of augmented X:\", X_train_augment.shape)\n",
        "print(\"Dimensions of y:\", y_train_augment.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jC31NVvggKP9"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "for i in range(100):\n",
        "  new_X = createAugmentedImage(X_train[i])\n",
        "  new_y = y_train[i]\n",
        "\n",
        "  if i == 0:\n",
        "    X_train_augment = [new_X]\n",
        "    y_train_augment = [new_y]\n",
        "  else:\n",
        "    X_train_augment = np.append(X_train_augment, [new_X], axis=0)\n",
        "    y_train_augment = np.append(y_train_augment, [new_y], axis=0)\n",
        "\n",
        "\n",
        "print(\"Dimensions of augmented X:\", X_train_augment.shape)\n",
        "print(\"Dimensions of y:\", y_train_augment.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLRV881W1N_S"
      },
      "source": [
        "## Exercise 1C\n",
        "\n",
        "Train your model (```cnn_model```) for 5 additional epochs using your new augmented dataset.\n",
        "\n",
        "Use your testing data as validation to look at model performance as it trains.\n",
        "\n",
        "Note: you do not need to start over with training, just start from where the model left off.\n",
        "\n",
        "Does the augmented dataset improve performance? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpZ-YPOk1hW-"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X39VJBeu1lJd"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "additional_history = cnn_model.fit(X_train_augment, y_train_augment, validation_data=(X_test, y_test), epochs=5)\n",
        "plot_metric(additional_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YX9jPM3hat-"
      },
      "source": [
        "# PART II: Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lypoFyleByI"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ab/Transfer_Learning.png\" width=500>\n",
        "\n",
        "No matter what the image classification task, we expect certain **geometric features** to be important - lines, edges, shapes, etc. We also expect convolutional neural networks to learn to recognize these shapes (most likely in the earlier layers) throughout their training. Therefore, we might be able to re-use the layers/weights (that presumably encode for recognizing lines, edges, etc.) that one image classification task has learned to perform another.\n",
        "\n",
        "Many groups have published large neural networks trained on millions of images for classification tasks - Resnet, AlexNet, and MobileNet are a few famous ones. In order to perform transfer learning we can\n",
        "1. Download one of these pretrained models - their weights have already been learned.\n",
        "2. Change the output layer to have the number of nodes appropriate for our classification task (# of classes). Optionally, change the structure of any additional later layers you might want to alter.\n",
        "3. Freeze the weights of most of the layers, especially the initial first few layers. This is an option you can specify before training the model, and will prevent model training from changing any of those weights. Don't freeze the last layer.\n",
        "4. Alter your training images so that they are the right size for the input size of the downloaded neural network.\n",
        "5. Train the model on your images/labels!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L53eEc-z2p0T"
      },
      "source": [
        "## üì∂ Initialize a pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HAjTuRn1zUT"
      },
      "source": [
        "### Exercise 2A\n",
        "\n",
        "For our transfer learning, we're going to use 'experts' built upon the famous 'ImageNet' classification problem.\n",
        "\n",
        "In ImageNet, participants were challenged to build machine learning models that could distinguish 14 million images' categories, where there were > 20,000 categories available.\n",
        "\n",
        "Below, we see examples of 3 different categories.\n",
        "\n",
        "![](https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/ImageNet.jpg)\n",
        "\n",
        "This model will already have some object recognition expertise baked into it! We'll utilize this expertise by loading in this model, and we'll adapt it to our problem by replacing the last layer with a layer that we'll train ourselves.\n",
        "\n",
        "\n",
        "Run the next cell to perform step 1, intializing one this large model.\n",
        "\n",
        "Additionally, look at the summary of the model and answer:\n",
        "- What is the input size of the images that VGG16 can classify?\n",
        "- How many different categories of images does VGG16 classify?\n",
        "- How many different weights (parameters) did VGG16 learn when it was originally trained?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOaSY9V93OFY"
      },
      "outputs": [],
      "source": [
        "# Run this cell to import pretrained MobileNet\n",
        "from keras.applications import MobileNetV2, VGG16\n",
        "mobile_net = VGG16(include_top=True)\n",
        "mobile_net.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnA4Zgw632Ec"
      },
      "source": [
        "## üß∞ Modifying the output layer size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEtgd-dAeB8h"
      },
      "source": [
        "### Exercise 2B\n",
        "\n",
        "Perform Step (2), rewiring the network to have an output layer with the # of nodes appropriate for our classification task.\n",
        "\n",
        "After doing this, look at the final layer in your model. Does it have the number of neurons that you would like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1AsDT3sgKp_"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "\n",
        "\n",
        "# Make a final layer. Use a Dense() layer, with the size as\n",
        "# the number of of classes you want to predict!\n",
        "# Also set the activation function to softmax.\n",
        "new_output_layer = mobile_net.layers[0] ### REPLACE THIS LINE ###\n",
        "\n",
        "\n",
        "# Rewire the model so that the new output layer\n",
        "# The syntax here can be a little confusing, so we've helped you out.\n",
        "output = new_output_layer(mobile_net.layers[-2].output)\n",
        "input = mobile_net.input\n",
        "transfer_cnn = Model(input, output)\n",
        "\n",
        "\n",
        "# print the summary\n",
        "transfer_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iHG22EqhVntr"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "from keras import Model\n",
        "\n",
        "# Make a final layer. Use a Dense() layer, with the size as\n",
        "# the number of of classes you want to predict!\n",
        "# Also set the activation function to softmax.\n",
        "new_output_layer = Dense(len(y_train[0]), activation='softmax') ### REPLACE THIS LINE ###\n",
        "\n",
        "# Rewire the model so that the new output layer\n",
        "# The syntax here can be a little confusing, so we've helped you out.\n",
        "output = new_output_layer(mobile_net.layers[-2].output)\n",
        "input = mobile_net.input\n",
        "transfer_cnn = Model(input, output)\n",
        "\n",
        "# print the summary\n",
        "transfer_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIw_S3Z44Rd4"
      },
      "source": [
        "## üßä Freezing the weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQBZeFLSeCRZ"
      },
      "source": [
        "### Exercise 2C\n",
        "\n",
        "Next, freeze the weights for all of the layers except for the final layer. You can do this by setting\n",
        "```layer.trainable=False``` where ```layer``` is the layer you are interested in freezing (``trainable=False``) or unfreezing (``trainable=True``) the weights of.\n",
        "\n",
        "Additionally, compile your model and look at its summary.\n",
        " Now, how many trainable parameters (weights) are there compared to before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To_qkLeugLGU"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for layer in transfer_cnn.layers:\n",
        "    layer.trainable = True ### YOUR CODE HERE - Make sure all layers are >>>NOT<<<< trainable\n",
        "\n",
        "## Set the final layer as trainable=True\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "# Compile your new model using loss='categorical_crossentropy'\n",
        "# optimizer='adam' and metrics=['accuracy', 'categorical_crossentropy']\n",
        "### YOUR CODE HERE ####\n",
        "\n",
        "# Look at the summary of the network to make sure the structure is as you expect!\n",
        "transfer_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pMZnApXbgLGV"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for layer in transfer_cnn.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "## Set the final layer as trainable=True\n",
        "transfer_cnn.layers[-1].trainable = True\n",
        "\n",
        "# Compile your new model using loss='categorical_crossentropy'\n",
        "# optimizer='adam' and metrics=['accuracy', 'categorical_crossentropy']\n",
        "transfer_cnn.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                     metrics=['accuracy', 'categorical_crossentropy'])\n",
        "# Look at the summary of the network to make sure the structure is as you expect!\n",
        "transfer_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vL-ugLi5WKh"
      },
      "source": [
        "## ‚úÇ Resize your images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PNlMBAeCuT"
      },
      "source": [
        "### Exercise 2D\n",
        "\n",
        "Resize your images so that they are the appropriate size for the input layer of your model. You can use the function we have given you, which takes in a set of ```images``` and resizes them to have the appropriate ```heights``` and ```weights```.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hpRZIhEgLfE"
      },
      "outputs": [],
      "source": [
        "# Takes in an image, a new height, and a new width\n",
        "# and resizes the image, plus converts from greyscale to 3 RGB color channels.\n",
        "def ResizeImages(images, height, width):\n",
        "  return np.array([resize_with_pad(image, height, width, antialias=True) for image in images]).astype(int)\n",
        "\n",
        "# Resize your image\n",
        "X_train_resized = X_train ### REPLACE THIS LINE\n",
        "X_test_resized = X_test ### REPLACE THIS LINE\n",
        "\n",
        "# Make sure your images are the right dimensions\n",
        "print(\"Dim X_train_resized:\", X_train_resized.shape)\n",
        "print(\"Dim X_test_resized:\", X_test_resized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RyM-a7yBgLfF"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "def ResizeImages(images, height, width):\n",
        "  return np.array([resize_with_pad(image, height, width, antialias=True) for image in images]).astype(int)\n",
        "\n",
        "X_train_resized = ResizeImages(X_train, 224, 224)\n",
        "X_test_resized = ResizeImages(X_test, 224, 224)\n",
        "\n",
        "# Make sure your images are the right dimensions\n",
        "print(\"Dim X_train_resized:\", X_train_resized.shape)\n",
        "print(\"Dim X_test_resized:\", X_test_resized.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mzm-uHL6JSK"
      },
      "source": [
        "## üíÖ Finetune the model using your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Vyh4Z36XEH"
      },
      "source": [
        "### Exercise 2E\n",
        "\n",
        "Finally, train your model using your data. Because this model takes a while to train, just train for 3 epochs.\n",
        "\n",
        "Use your testing data as validation to look at model performance as it trains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUXYwb-m6k3X"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr_okZzp6mI5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Instructor Solution\n",
        "transfer_history = transfer_cnn.fit(X_train_resized, y_train, validation_data=(X_test_resized, y_test), epochs=10)\n",
        "plot_metric(transfer_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvep9HMLfGGb"
      },
      "source": [
        "# PART III: Wrapping Up\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Congrats!!! You used some very advanced techniques to build a sophisticated machine learning model! If you didn't understand everything, ***don't worry!*** Transfer learning especially is a very modern field and is still being explored.\n",
        "\n",
        "<img src=\"https://c.pxhere.com/photos/04/45/fireworks_celebration_bright_pink_explosive_celebrate_display_july_4th-1160027.jpg!d\" width=500>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HjOhlp462O6"
      },
      "source": [
        "### Exercise 3A\n",
        "\n",
        "To wrap up, answer the following questions:\n",
        "\n",
        "(1) Did data augmentation or transfer learning work better to improve the performance of your model? Why do you think one worked better than the other?\n",
        "\n",
        "(2) What might be a better type of data augmentation strategy to use for your data?\n",
        "\n",
        "(3) What might be a better type of dataset to use for transfer learning?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Sg44rM7WEL"
      },
      "source": [
        "## üî≠ Looking back on your project\n",
        "\n",
        "Just like our neural networks are able to *learn* from data and improve performance, so can you!\n",
        "\n",
        "Therefore, let's do a little retrospective for this project, and talk about what went well and what was challenging.\n",
        "\n",
        "We'll do this in a fun little game called: rose-thorn-bud. Discuss with your team and with the rest of the class!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbfYG_1rjC4c"
      },
      "source": [
        "### Exercise 3B\n",
        "\n",
        "üåπ Rose: What went well in the project in terms of...\n",
        "\n",
        "- model performance? In what areas did your model perform well in?\n",
        "- coding? What parts of the code did you feel like you mastered by the end of the project?\n",
        "- teamwork? What methods did you use to collaborate with your teammates?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8OtHd1L9uKg"
      },
      "source": [
        "### Exercise 3C\n",
        "\n",
        "üî∫ Thorn: What was challenging in the project in terms of...\n",
        "\n",
        "- model performance? In what areas did your model perform poorly?\n",
        "- coding? What parts of the code did you feel like you could use more work on?\n",
        "- teamwork? What was something your team struggled with during the project?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ib7QY2-AdG"
      },
      "source": [
        "### Exercise 3D\n",
        "\n",
        "üå± Bud: What are some future directions for your project in terms of...\n",
        "\n",
        "- model performance? If you had infinite time and resources, what strategies might you take to improve your model even more?\n",
        "- coding? What parts of the coding or machine learning concepts would you like to dive deeper into?\n",
        "- teamwork? What are some ways to work better as a team that you are excited to try next time you are in a group project?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}